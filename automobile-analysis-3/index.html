<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.useso.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="汽车口碑分析,scrapy," />





  <link rel="alternate" href="/rss2.xml" title="Wenyu's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="环境配置 Ubuntu 16.04 Python 3.5  技术框架 Scrapy  需求目标本项目为汽车口碑分析，第一步需要爬取对于不同车型的评论数据。 选择58车的车型分类爬取评论数据。">
<meta name="keywords" content="汽车口碑分析,scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="【汽车口碑分析】3.爬取汽车评论数据">
<meta property="og:url" content="https://tianwenyu.github.io/automobile-analysis-3/index.html">
<meta property="og:site_name" content="Wenyu&#39;s Blog">
<meta property="og:description" content="环境配置 Ubuntu 16.04 Python 3.5  技术框架 Scrapy  需求目标本项目为汽车口碑分析，第一步需要爬取对于不同车型的评论数据。 选择58车的车型分类爬取评论数据。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/jB04IJjkLk.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/5j7LE7l1EB.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/9KaKELGGj7.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/24mD9Kk40g.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/GDkBDcE9A8.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/3jJH33i5lI.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/1IG8ef6j92.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/6Bl97dCa4D.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180207/3bDiLjmH2b.png?imageslim">
<meta property="og:image" content="http://p15qizl76.bkt.clouddn.com/blog/180207/42KlbG9aFe.png?imageslim">
<meta property="og:updated_time" content="2018-02-07T02:22:56.816Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【汽车口碑分析】3.爬取汽车评论数据">
<meta name="twitter:description" content="环境配置 Ubuntu 16.04 Python 3.5  技术框架 Scrapy  需求目标本项目为汽车口碑分析，第一步需要爬取对于不同车型的评论数据。 选择58车的车型分类爬取评论数据。">
<meta name="twitter:image" content="http://p15qizl76.bkt.clouddn.com/blog/180206/jB04IJjkLk.png?imageslim">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: undefined,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="https://tianwenyu.github.io/automobile-analysis-3/"/>

  <title> 【汽车口碑分析】3.爬取汽车评论数据 | Wenyu's Blog </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  








  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div style="display: none;">
    <script src="//s6.cnzz.com/stat.php?id=1271854965&web_id=1271854965" type="text/javascript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-right page-post-detail ">
    <div class="headband"></div>
    
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader" style="background-image: url('/images/home_bg.jpg');">
      <div class="header-inner"><a class="site-home" href="/">Wenyu's Blog</a>

<div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <div href="/"  class="brand">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Wenyu's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </div>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            博文归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签云
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <input type="text" id="local-search-input">
 <span class="search-icon fa fa-search"></span>
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
      <div class="header-post"> 
  <div class="post-header">
      <div class="tags">
      
        <a href="/tags/汽车口碑分析/" rel="tag" title="汽车口碑分析">汽车口碑分析</a>
      
        <a href="/tags/scrapy/" rel="tag" title="scrapy">scrapy</a>
      
      </div>
      <h1>【汽车口碑分析】3.爬取汽车评论数据</h1>
      <h2 class="subtitle"></h2>
      <div class="post-time">
        <span class="post-meta-item-text">发表于 </span>
        <time itemprop="dateCreated" datetime="2018-02-03T20:29:30+08:00" content="2018-02-03" title="2018-02-03 20:29:30">
          2018-02-03
        </time>
      </div>
  </div>
 </div>
    </header>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                【汽车口碑分析】3.爬取汽车评论数据
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-02-03T20:29:30+08:00" content="2018-02-03">
              2018-02-03
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/项目/" itemprop="url" rel="index">
                    <span itemprop="name">项目</span>
                  </a>
                </span>

                
                

              
            </span>
          

          <!-- 
            
           -->

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ul>
<li>Ubuntu 16.04</li>
<li>Python 3.5</li>
</ul>
<h2 id="技术框架"><a href="#技术框架" class="headerlink" title="技术框架"></a>技术框架</h2><ul>
<li>Scrapy</li>
</ul>
<h2 id="需求目标"><a href="#需求目标" class="headerlink" title="需求目标"></a>需求目标</h2><p>本项目为汽车口碑分析，第一步需要爬取对于不同车型的评论数据。</p>
<p>选择<a href="http://www.58che.com/brand.html" target="_blank" rel="external">58车</a>的车型分类爬取评论数据。</p>
<a id="more"></a>
<h2 id="爬取流程"><a href="#爬取流程" class="headerlink" title="爬取流程"></a>爬取流程</h2><ol>
<li><p>先获取每个车型的链接，以下图中红框内的车型为例</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/jB04IJjkLk.png?imageslim" alt="mark"></p>
</li>
<li><p>打开链接后，抓取下图红框中的总评分，写入文件中。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/5j7LE7l1EB.png?imageslim" alt="mark"></p>
</li>
<li><p>写入总评分后，通过拼接链接进入该车型的用户评论页面。</p>
<p>通过第一步中获取的链接拼接上<code>list_s1_p1.html</code>，组成用户评论页面的链接。</p>
<p>【注】此为第一页的链接，若还有下一页，下述步骤会提及处理方法。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/9KaKELGGj7.png?imageslim" alt="mark"></p>
</li>
<li><p>抓取评论页面中的各种数据，如<code>id</code>，<code>评分</code>，<code>评论</code>等。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/24mD9Kk40g.png?imageslim" alt="mark"></p>
</li>
<li><p>若该评论页面还有<code>下一页</code>，则继续抓取下一页中的评论数据。</p>
<p>【方法】</p>
<p>判断页面中是否有<code>下一页</code>元素，若有则回调解析评论页面的方法。</p>
</li>
<li><p>将爬取的数据保存到文件中。</p>
</li>
</ol>
<h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="创建新工程"><a href="#创建新工程" class="headerlink" title="创建新工程"></a>创建新工程</h3><p>先创建工程目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/t/dataset/</span><br><span class="line">mkdir carSpider</span><br></pre></td></tr></table></figure>
<p>创建新工程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scrapy startproject carSpider</span><br></pre></td></tr></table></figure>
<h3 id="编辑items-py文件"><a href="#编辑items-py文件" class="headerlink" title="编辑items.py文件"></a>编辑<code>items.py</code>文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CarspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    file=scrapy.Field() <span class="comment">#文件名</span></span><br><span class="line">    car=scrapy.Field() <span class="comment">#车型</span></span><br><span class="line">    score=scrapy.Field() <span class="comment">#总评分</span></span><br><span class="line">    u_id=scrapy.Field() <span class="comment">#用户ID</span></span><br><span class="line">    u_score=scrapy.Field() <span class="comment">#用户评分</span></span><br><span class="line">    u_merit=scrapy.Field() <span class="comment">#用户评论优点</span></span><br><span class="line">    u_demerit=scrapy.Field() <span class="comment">#用户评论缺点</span></span><br><span class="line">    u_summary=scrapy.Field() <span class="comment">#用户评论综述</span></span><br><span class="line">    u_flower=scrapy.Field() <span class="comment">#用户评论鲜花数</span></span><br><span class="line">    u_brick=scrapy.Field() <span class="comment">#用户评论板砖数</span></span><br></pre></td></tr></table></figure>
<h3 id="编写carSpider-py文件"><a href="#编写carSpider-py文件" class="headerlink" title="编写carSpider.py文件"></a>编写<code>carSpider.py</code>文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> carSpider.items <span class="keyword">import</span> CarspiderItem</span><br><span class="line"></span><br><span class="line">baseDir = <span class="string">'/home/t/dataset/carRemark/'</span></span><br><span class="line">startUrl=<span class="string">'http://www.58che.com/brand.html'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CarSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name=<span class="string">'spider'</span> <span class="comment">#爬虫名</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.start_urls=[startUrl] </span><br><span class="line"></span><br><span class="line">    <span class="comment">#第一层解析方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">		<span class="comment">#定位到车型元素</span></span><br><span class="line">        subclasses=response.css(<span class="string">'body &gt; div.fltop &gt; div.marcenter &gt; div &gt; div &gt; div.r &gt; ul &gt; li &gt; dl &gt; dt &gt; a'</span>)</span><br><span class="line">        <span class="keyword">for</span> subclass <span class="keyword">in</span> subclasses:</span><br><span class="line">            subclass_name=subclass.xpath(<span class="string">'text()'</span>).extract_first() <span class="comment">#获取车型名称文本</span></span><br><span class="line">            subclass_link=subclass.xpath(<span class="string">'@href'</span>).extract_first() <span class="comment">#获取车型链接</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=subclass_link,callback=self.parse_car_subclass,meta=&#123;<span class="string">'file'</span>:subclass_name&#125;) <span class="comment">#回调下一层解析方法，并把车型名称传递给该方法作为文件名</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#第二层解析方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_car_subclass</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        infos=response.css(<span class="string">'#line1 &gt; div.cars_line2.l &gt; div.dianpings &gt; div.d_div1.clearfix &gt; font'</span>) <span class="comment">#定位到总评分元素</span></span><br><span class="line">        <span class="keyword">for</span> info <span class="keyword">in</span> infos:</span><br><span class="line">            score=info.xpath(<span class="string">'text()'</span>).extract_first() <span class="comment">#获取总评分元素文本</span></span><br><span class="line">            file=response.meta[<span class="string">'file'</span>] <span class="comment">#获取上个Request传递来的meta['file']</span></span><br><span class="line">            self.writeScore(file,score) <span class="comment">#将总评分写入文件中</span></span><br><span class="line">            link=response.url+<span class="string">'list_s1_p1.html'</span> <span class="comment">#拼接用户评论第一页链接</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=link,callback=self.parse_remark,meta=&#123;<span class="string">'file'</span>:file&#125;) <span class="comment">#回调下一层解析方法，把车型名称传递给该方法作为文件名</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#第三层解析方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_remark</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="comment">#定位到用户评论元素</span></span><br><span class="line">        infos=response.css(<span class="string">'body &gt; div.newbox &gt; div &gt; div.xgo_cars_w760.l &gt; div.xgo_dianping_infos.mb10 &gt; div.xgo_cars_dianping &gt; div &gt; dl'</span>)</span><br><span class="line">        <span class="keyword">for</span> info <span class="keyword">in</span> infos:</span><br><span class="line">            uid=info.xpath(<span class="string">'dd[1]/strong/a/text()'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取用户ID</span></span><br><span class="line">            score=info.xpath(<span class="string">'dd[1]/div/div/@style'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取用户评分星级</span></span><br><span class="line">            score=self.getScore(score) <span class="comment">#将用户评分星级转化为5分制评分</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment">#先获取是否有‘优点’元素，若有则定位‘优点’元素的下一个兄弟节点，即‘优点评语’，若无则为空</span></span><br><span class="line">                node=info.xpath(<span class="string">'dd[2]/div/div[contains(@class,"l redc00")]'</span>)[<span class="number">0</span>] </span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                    merit=node.xpath(<span class="string">'following-sibling::*[1]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    merit=<span class="string">''</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                merit=<span class="string">''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment">#先获取是否有‘缺点’元素，若有则定位‘缺点’元素的下一个兄弟节点，即‘缺点评语’，若无则为空</span></span><br><span class="line">                node=info.xpath(<span class="string">'dd[2]/div/div[contains(@class,"l hei666")]'</span>)[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                    demerit=node.xpath(<span class="string">'following-sibling::*[1]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    demerit=<span class="string">''</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                demerit=<span class="string">''</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment">#先获取是否有‘综述’元素，若有则定位‘综述’元素的下一个兄弟节点，即‘综述评语’，若无则为空</span></span><br><span class="line">                node=info.xpath(<span class="string">'dd[2]/div/div[contains(@class,"l")]'</span>)[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                    summary=node.xpath(<span class="string">'following-sibling::*[1]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    summary=<span class="string">''</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                summary=<span class="string">''</span></span><br><span class="line"></span><br><span class="line">            flower=info.xpath(<span class="string">'dd[2]/div[contains(@class,"apply")]/a[3]/span/text()'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取鲜花数</span></span><br><span class="line">            brick=info.xpath(<span class="string">'dd[2]/div[contains(@class,"apply")]/a[4]/span/text()'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取板砖数</span></span><br><span class="line"></span><br><span class="line">		   <span class="comment">#创建Item</span></span><br><span class="line">            item=CarspiderItem()</span><br><span class="line">            item[<span class="string">'file'</span>]=response.meta[<span class="string">'file'</span>]</span><br><span class="line">            item[<span class="string">'u_id'</span>]=uid</span><br><span class="line">            item[<span class="string">'u_score'</span>]=score</span><br><span class="line">            item[<span class="string">'u_merit'</span>]=merit</span><br><span class="line">            item[<span class="string">'u_demerit'</span>]=demerit</span><br><span class="line">            item[<span class="string">'u_summary'</span>]=summary</span><br><span class="line">            item[<span class="string">'u_flower'</span>]=flower</span><br><span class="line">            item[<span class="string">'u_brick'</span>]=brick</span><br><span class="line"></span><br><span class="line">            <span class="comment">#生成Item</span></span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#获取`下一页`元素，若有则回调`parse_remark`第三层解析方法，即继续获取下一页用户评论数据</span></span><br><span class="line">        <span class="comment">#定位`下一页`元素</span></span><br><span class="line">        next_pages=response.css(<span class="string">'body &gt; div.newbox &gt; div &gt; div.xgo_cars_w760.l &gt; div.xgo_dianping_infos.mb10 &gt; div.xgo_cars_dianping &gt; div &gt; div &gt; a.next'</span>)</span><br><span class="line">        <span class="keyword">for</span> next_page <span class="keyword">in</span> next_pages:</span><br><span class="line">            <span class="comment">#若有`下一页`元素，则拼接`下一页`元素链接，并回调第三层解析方法，用来获取下一页用户评论数据</span></span><br><span class="line">            <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                next_page_link=next_page.xpath(<span class="string">'@href'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">                next_page_link=<span class="string">'http://www.58che.com'</span>+next_page_link</span><br><span class="line">                file=response.meta[<span class="string">'file'</span>]</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(url=next_page_link, callback=self.parse_remark, meta=&#123;<span class="string">'file'</span>: file&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">#将总评分写入文件</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">writeScore</span><span class="params">(self,file,score)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'/home/t/dataset/carRemark/'</span>+file+<span class="string">'.json'</span>,<span class="string">'a+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(score+<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将用户评分星级转为5分制分数，类似switch功能</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getScore</span><span class="params">(self,text)</span>:</span></span><br><span class="line">        text=text.split(<span class="string">':'</span>)[<span class="number">1</span>] <span class="comment">#分割文本，原文本格式形如`width:100%`，分割并截取`:`后的文本</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">'100%'</span>:<span class="number">5</span>,</span><br><span class="line">            <span class="string">'80%'</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="string">'60%'</span>:<span class="number">3</span>,</span><br><span class="line">            <span class="string">'40%'</span>:<span class="number">2</span>,</span><br><span class="line">            <span class="string">'20%'</span>:<span class="number">1</span>,</span><br><span class="line">            <span class="string">'0%'</span>:<span class="number">0</span></span><br><span class="line">        &#125;.get(text)</span><br></pre></td></tr></table></figure>
<p>【解析】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定位到用户评论元素</span></span><br><span class="line">   infos=response.css(<span class="string">'body &gt; div.newbox &gt; div &gt; div.xgo_cars_w760.l &gt; div.xgo_dianping_infos.mb10 &gt; div.xgo_cars_dianping &gt; div &gt; dl'</span>)</span><br></pre></td></tr></table></figure>
<p>此句代码定位的元素如下图所示，定位到的是评论页面每条评论的元素整体。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/GDkBDcE9A8.png?imageslim" alt="mark"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> info <span class="keyword">in</span> infos:</span><br><span class="line">           uid=info.xpath(<span class="string">'dd[1]/strong/a/text()'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取用户ID</span></span><br><span class="line">           score=info.xpath(<span class="string">'dd[1]/div/div/@style'</span>)[<span class="number">0</span>].extract() <span class="comment">#获取用户评分星级</span></span><br><span class="line">           score=self.getScore(score) <span class="comment">#将用户评分星级转化为5分制评分</span></span><br></pre></td></tr></table></figure>
<p><code>uid</code>定位到的元素如下图所示，</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/3jJH33i5lI.png?imageslim" alt="mark"></p>
<p><code>score</code>定位到的元素如下图所示，获取<code>score</code>元素的<code>style</code>属性，值形如<code>width:80%</code>，需要通过<code>getScore()</code>方法转换为五分制分数。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/1IG8ef6j92.png?imageslim" alt="mark"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	<span class="comment">#先获取是否有‘优点’元素，若有则定位‘优点’元素的下一个兄弟节点，即‘优点评语’，若无则为空</span></span><br><span class="line">	node=info.xpath(<span class="string">'dd[2]/div/div[contains(@class,"l redc00")]'</span>)[<span class="number">0</span>] </span><br><span class="line">	<span class="keyword">if</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">		merit=node.xpath(<span class="string">'following-sibling::*[1]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		merit=<span class="string">''</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">	merit=<span class="string">''</span></span><br></pre></td></tr></table></figure>
<p>先定位是否有<code>优点</code>元素，如下图红框所示，若有该元素，则获取<code>优点</code>元素的下一个兄弟节点内容，如下图蓝框所示，若无则为空。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180206/6Bl97dCa4D.png?imageslim" alt="mark"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#获取`下一页`元素，若有则回调`parse_remark`第三层解析方法，即继续获取下一页用户评论数据</span></span><br><span class="line"><span class="comment">#定位`下一页`元素</span></span><br><span class="line">next_pages=response.css(<span class="string">'body &gt; div.newbox &gt; div &gt; div.xgo_cars_w760.l &gt; div.xgo_dianping_infos.mb10 &gt; div.xgo_cars_dianping &gt; div &gt; div &gt; a.next'</span>)</span><br><span class="line">	<span class="keyword">for</span> next_page <span class="keyword">in</span> next_pages:</span><br><span class="line">		<span class="comment">#若有`下一页`元素，则拼接`下一页`元素链接，并回调第三层解析方法，用来获取下一页用户评论数据</span></span><br><span class="line">		<span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">			next_page_link=next_page.xpath(<span class="string">'@href'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">             next_page_link=<span class="string">'http://www.58che.com'</span>+next_page_link</span><br><span class="line">             file=response.meta[<span class="string">'file'</span>]</span><br><span class="line">             <span class="keyword">yield</span> scrapy.Request(url=next_page_link, callback=self.parse_remark, meta=&#123;<span class="string">'file'</span>: file&#125;)</span><br></pre></td></tr></table></figure>
<p>解析完上述内容，判断用户评论页面是否有分页，定位是否有<code>下一页</code>元素，如下图红框所示，若有则获取该元素链接，如下图橙框所示。</p>
<p>获取之后，回调<code>parse_remark</code>方法解析下一页的评论页面。</p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180207/3bDiLjmH2b.png?imageslim" alt="mark"></p>
<h2 id="编辑pipelines-py文件"><a href="#编辑pipelines-py文件" class="headerlink" title="编辑pipelines.py文件"></a>编辑<code>pipelines.py</code>文件</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line">baseDir = <span class="string">'/home/t/dataset/carRemark/'</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CarspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        print(item[<span class="string">'file'</span>])</span><br><span class="line">        <span class="keyword">with</span> codecs.open(baseDir+item[<span class="string">'file'</span>]+<span class="string">'.json'</span>,<span class="string">'a+'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            line=json.dumps(dict(item),ensure_ascii=<span class="keyword">False</span>)+<span class="string">'\n'</span></span><br><span class="line">            f.write(line)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h2 id="编辑settings-py文件"><a href="#编辑settings-py文件" class="headerlink" title="编辑settings.py文件"></a>编辑<code>settings.py</code>文件</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Scrapy settings for carSpider project</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For simplicity, this file contains only settings considered important or</span></span><br><span class="line"><span class="comment"># commonly used. You can find more settings consulting the documentation:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://doc.scrapy.org/en/latest/topics/settings.html</span></span><br><span class="line"><span class="comment">#     http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#     http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line">BOT_NAME = <span class="string">'carSpider'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'carSpider.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'carSpider.spiders'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line"><span class="comment">#USER_AGENT = 'carSpider (+http://www.yourdomain.com)'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS = 32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure a delay for requests for the same website (default: 0)</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay</span></span><br><span class="line"><span class="comment"># See also autothrottle settings and docs</span></span><br><span class="line"><span class="comment">#DOWNLOAD_DELAY = 3</span></span><br><span class="line"><span class="comment"># The download delay setting will honor only one of:</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_DOMAIN = 16</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_IP = 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable cookies (enabled by default)</span></span><br><span class="line"><span class="comment">#COOKIES_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable Telnet Console (enabled by default)</span></span><br><span class="line"><span class="comment">#TELNETCONSOLE_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line"><span class="comment">#DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',</span></span><br><span class="line"><span class="comment">#   'Accept-Language': 'en',</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable spider middlewares</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"><span class="comment">#SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    'carSpider.middlewares.CarspiderSpiderMiddleware': 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#DOWNLOADER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    'carSpider.middlewares.MyCustomDownloaderMiddleware': 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable extensions</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/extensions.html</span></span><br><span class="line"><span class="comment">#EXTENSIONS = &#123;</span></span><br><span class="line"><span class="comment">#    'scrapy.extensions.telnet.TelnetConsole': None,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'carSpider.pipelines.CarspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable and configure the AutoThrottle extension (disabled by default)</span></span><br><span class="line"><span class="comment"># See http://doc.scrapy.org/en/latest/topics/autothrottle.html</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_ENABLED = True</span></span><br><span class="line"><span class="comment"># The initial download delay</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_START_DELAY = 5</span></span><br><span class="line"><span class="comment"># The maximum download delay to be set in case of high latencies</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_MAX_DELAY = 60</span></span><br><span class="line"><span class="comment"># The average number of requests Scrapy should be sending in parallel to</span></span><br><span class="line"><span class="comment"># each remote server</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span></span><br><span class="line"><span class="comment"># Enable showing throttling stats for every response received:</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_DEBUG = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable and configure HTTP caching (disabled by default)</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span></span><br><span class="line">HTTPCACHE_ENABLED = <span class="keyword">False</span></span><br><span class="line"><span class="comment">#HTTPCACHE_EXPIRATION_SECS = 0</span></span><br><span class="line"><span class="comment">#HTTPCACHE_DIR = 'httpcache'</span></span><br><span class="line"><span class="comment">#HTTPCACHE_IGNORE_HTTP_CODES = []</span></span><br><span class="line"><span class="comment">#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br></pre></td></tr></table></figure>
<p>【解析】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p>将原来的<code>True</code>改为<code>False</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'carSpider.pipelines.CarspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将原来的注释去掉，即注册pipelines，否则无法使用该pipelines。</p>
<h2 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h2><p>在项目根目录下新建文件<code>entrypoint.py</code></p>
<p><img src="http://p15qizl76.bkt.clouddn.com/blog/180207/42KlbG9aFe.png?imageslim" alt="mark"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line">execute([<span class="string">'scrapy'</span>,<span class="string">'crawl'</span>,<span class="string">'spider'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="项目源码"><a href="#项目源码" class="headerlink" title="项目源码"></a>项目源码</h2><p><a href="https://github.com/tianwenyu/58CheSpider" target="_blank" rel="external">Github地址</a></p>

        
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/汽车口碑分析/" rel="tag">#汽车口碑分析</a>
          
            <a href="/tags/scrapy/" rel="tag">#scrapy</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/spark-pycharm/" rel="next" title="【分布式编程】四——Pycharm运行Python版Spark程序">
                <i class="fa fa-chevron-left"></i> 【分布式编程】四——Pycharm运行Python版Spark程序
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/seaborn/" rel="prev" title="Seaborn库的使用">
                Seaborn库的使用 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">77</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">标签云</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/rss2.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/tianwenyu" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#环境配置"><span class="nav-text">环境配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#技术框架"><span class="nav-text">技术框架</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#需求目标"><span class="nav-text">需求目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#爬取流程"><span class="nav-text">爬取流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#详细步骤"><span class="nav-text">详细步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建新工程"><span class="nav-text">创建新工程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编辑items-py文件"><span class="nav-text">编辑items.py文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编写carSpider-py文件"><span class="nav-text">编写carSpider.py文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编辑pipelines-py文件"><span class="nav-text">编辑pipelines.py文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编辑settings-py文件"><span class="nav-text">编辑settings.py文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行爬虫"><span class="nav-text">运行爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#项目源码"><span class="nav-text">项目源码</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/BearD01001/hexo-theme-nextd">
    NexTD
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




    <link rel='stylesheet' href='https://imsun.github.io/gitment/style/default.css'>
    <style>
        .gitment-editor-avatar {
            border-bottom: none !important;
        }
        .gitment-container a:hover {
            text-decoration: none !important;
        }
        .gitment-markdown a,
        .gitment-footer-project-link {
            color: #555 !important;
        }
        .gitment-footer-project-link:hover,
        .gitment-editor-logout-link:hover,
        .gitment-editor-footer-tip:hover,
        .gitment-header-issue-link:hover,
        .gitment-comment-name:hover,
        .gitment-markdown a:hover {
            color: #222 !important;
        }
    </style>
    <script src='https://imsun.github.io/gitment/dist/gitment.browser.js'></script>
    <script type='text/javascript'>
        (function() {
            var id = window.location.pathname.replace(/(\/$)/g, '');
            var owner = 'tianwenyu';
            var repo = 'tianwenyu.github.io';
            var clientId = '7e6796bf4bd74a25333f';
            var clientSecret = 'd190223868b2175fbce4094e6485195cef7d3e8a';

            var gitment = new Gitment({
                id: id,
                owner: owner,
                repo: repo,
                oauth: {
                    client_id: clientId,
                    client_secret: clientSecret,
                },
            });
            gitment.render('comments');
        })();
    </script>



	





  



  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').fadeToggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ decodeURIComponent(data_url) +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').fadeOut(function() {
          $(".popoverlay").remove();
          $('body').css('overflow', '');
      });
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
